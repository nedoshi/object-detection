{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c06e224-7916-4b95-ab14-37ebd2e2b761",
   "metadata": {},
   "source": [
    "# gRPC Inference\n",
    "\n",
    "In this notebook we'll review how to consume the model through the RHODS Model Server using a gRPC endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266d645-f9c0-4f9e-8f1b-182cc54c6623",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First let's install dependencies.  In this case, we'll need some new packages for gRPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78286db-b216-4c14-ba2b-9235aaebe974",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grpcio grpcio-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52abdd-3b1d-4f13-9341-46ac36527585",
   "metadata": {},
   "source": [
    "Now we can set the host, port, and model name of our endpoint\n",
    "\n",
    "If you've deployed the model with a different name instead of `yolo`, you'll need to adjust the model name accordingly.\n",
    "\n",
    "If you've deployed the model to a different namespace, you'll have to modify the host.  Here we're assuming the kube service is in the same namespace, but we could refer to it in full with the namespace.  e.g. `modelmesh-serving.project-name.svc.cluster.local`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffad01-a4cc-4d96-b725-309655636768",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_host = 'modelmesh-serving'\n",
    "grpc_port = 8033\n",
    "model_name = 'yolo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c5ab8-70d4-4a34-ad1e-6ce3e34456dc",
   "metadata": {},
   "source": [
    "### gRPC Functions\n",
    "\n",
    "We generated python functions from the [kserve proto file](https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/grpc_predict_v2.proto). If you're new to gRPC, you can take a look at the [Python quickstart](https://grpc.io/docs/languages/python/quickstart/) to see how we generated `utils/grpc_predict_v2_pb2_grpc.py` and `utils/grpc_predict_v2_pb2`.\n",
    "\n",
    "Let's import functions from these generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21bed9-341a-4ba4-bb4a-4ca400f0189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import grpc\n",
    "import utils.grpc_predict_v2_pb2 as grpc_predict_v2_pb2\n",
    "import utils.grpc_predict_v2_pb2_grpc as grpc_predict_v2_pb2_grpc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d99cdb-282a-4539-b8d1-a7bbd8d66468",
   "metadata": {},
   "source": [
    "### Model Metadata\n",
    "\n",
    "The per-model metadata API provides information about a model. Errors are indicated by the google.rpc.Status returned for the request. The OK code indicates success and other codes indicate failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c930d9-2a06-4638-962e-841e8b034902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = [('grpc.max_receive_message_length', 100 * 1024 * 1024)]\n",
    "channel = grpc.insecure_channel(f\"{grpc_host}:{grpc_port}\", options=options)\n",
    "stub = grpc_predict_v2_pb2_grpc.GRPCInferenceServiceStub(channel)\n",
    "\n",
    "request = grpc_predict_v2_pb2.ModelMetadataRequest(name=model_name)\n",
    "response = stub.ModelMetadata(request)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09700100-703c-4a39-b028-4daf7b573b47",
   "metadata": {},
   "source": [
    "### Preprocessing Functions\n",
    "\n",
    "Now, we can import the preprocessing and rendering functions as normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f842c0-21b8-495a-b155-ef3ab1782391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.classes import coco_classes\n",
    "from utils.images import preprocess, postprocess, draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56606120-e2b3-4cdf-9b12-39f441f69b0f",
   "metadata": {},
   "source": [
    "### Making a gRPC Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027c49-fbe2-4a72-ac46-266ab0becbb6",
   "metadata": {},
   "source": [
    "Let's prepare one of our sample images as a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c78714-460e-40c7-b47d-2685f4b668b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/redhat-dog.jpg'\n",
    "transformed_image, scaling, padding = preprocess(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497994c1-3dd3-4e42-8eca-8a30149a4559",
   "metadata": {},
   "source": [
    "We also need to know the class labels of the objects the model has been trained to detect. In case of the default YOLO v5 model, we can take the default class labels defined in the _classes_ module.\n",
    "If you want to test a custom model, replace `coco_classes` with the list of your custom class labels, e.g.\n",
    "\n",
    "`['Laptop', 'Computer keyboard', 'Table']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842176a-27b0-4750-bc65-4fe107cb5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = coco_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb9cf-48c6-438c-a776-e06d013dcd0c",
   "metadata": {},
   "source": [
    "We'll now need to package the preprocessed image into a format that the model server can consume. RHODS Model Serving implements a generic prediction interface that allows to query the typical model formats through the HTTP POST method using a JSON request body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdc026-6119-4749-ab98-44d1828e64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload(img_data):\n",
    "    payload = []\n",
    "    payload.append(grpc_predict_v2_pb2.ModelInferRequest().InferInputTensor())\n",
    "    payload[0].name = \"images\"\n",
    "    payload[0].datatype = \"FP32\"\n",
    "    payload[0].shape.extend([1, 3, 640, 640])\n",
    "    arr = img_data.flatten()\n",
    "    payload[0].contents.fp32_contents.extend(arr)\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a32e3-5202-480c-bac7-3a12706ca963",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = create_payload(transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d859e1-f9d1-4801-be38-8db71cf8e31e",
   "metadata": {},
   "source": [
    "Let's now send the serialized image to the model server. The inference results will also be returned in a generic JSON structure, which we can unpack straightaway. We'll also apply the post-processing function we defined in the previous notebook to extract the familiar object properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb6c3-43d0-4fbb-a830-286c118218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import classes\n",
    "\n",
    "\n",
    "def transform_filter_results(result_arr):\n",
    "    prediction_columns_number = 5 + len(class_labels)  # Model returns model returns [xywh, conf, class0, class1, ...]\n",
    "    reshaped_result_arr = result_arr.reshape(1, int(int(result_arr.shape[0])/prediction_columns_number), prediction_columns_number)\n",
    "    sorted_result_arr = (reshaped_result_arr[0][reshaped_result_arr[0][:, 4].argsort()])[::-1]\n",
    "    return sorted_result_arr\n",
    "\n",
    "\n",
    "def grpc_request(inputs):\n",
    "    request = grpc_predict_v2_pb2.ModelInferRequest()\n",
    "    request.model_name = model_name\n",
    "    request.inputs.extend(inputs)\n",
    "\n",
    "    response = stub.ModelInfer(request)\n",
    "\n",
    "    result_arr = np.frombuffer(response.raw_output_contents[0], dtype=np.float32)\n",
    "    return transform_filter_results(result_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66568dae-81cd-41cd-80fd-645c39a08755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_objects = grpc_request(payload)\n",
    "objects = postprocess([raw_objects], class_labels)\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baed58-595b-49ff-86ed-c9921368a1a8",
   "metadata": {},
   "source": [
    "Let's now visualize the result as we did when we were experimenting with the model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96301c5-5198-420e-9ab6-3efd9e8e844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_boxes(image_path, objects, scaling, padding, class_labels)\n",
    "\n",
    "draw_boxes(image_path, *objects[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
