{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c06e224-7916-4b95-ab14-37ebd2e2b761",
   "metadata": {},
   "source": [
    "# REST Inference\n",
    "\n",
    "After deploying the model using RHODS Model Serving, we'd like to test the model deployment by sending images to the model server for real-time inference.\n",
    "\n",
    "In this notebook we'll review how to consume the model through the RHODS Model Server using a REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52abdd-3b1d-4f13-9341-46ac36527585",
   "metadata": {},
   "source": [
    "### Setup\n",
    "For testing the model deployment, our test script needs to know the address of the model server. Let's insert the **inference endpoint** that the RHODS Dashboard provides for the deployed model.\n",
    "\n",
    "This code assumes you've deployed a model with the name `yolo` in the same data science project as this notebook.\n",
    "\n",
    "```\n",
    "prediction_url = 'http://modelmesh-serving:8008/v2/models/yolo/infer'\n",
    "```\n",
    "\n",
    "If you've deployed the model with a different name instead of `yolo`, you'll need to adjust the model name accordingly.\n",
    "\n",
    "If you've deployed the model to a different namespace, you'll have to modify the URL.  Here we're assuming the kube service is in the same namespace, but we could refer to it in full with the namespace.  e.g. `http://modelmesh-serving.project-name.svc.cluster.local:8008/v2/models/yolo/infer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffad01-a4cc-4d96-b725-309655636768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model named yolo in the same project\n",
    "model_name = \"yolo\"\n",
    "prediction_url = f\"http://modelmesh-serving:8008/v2/models/{model_name}/infer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e878f-d3a1-4586-a569-44263bf4e4b8",
   "metadata": {},
   "source": [
    "## Preprocessing functions.\n",
    "\n",
    "As calling the APIs closely mirrors using the models,  we'll start by importing the preprocessing and rendering functions that we have worked with in the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48db30-205c-4458-8f84-2e55599db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from requests import post\n",
    "import torch\n",
    "\n",
    "from utils.classes import coco_classes\n",
    "from utils.images import preprocess, postprocess, draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027c49-fbe2-4a72-ac46-266ab0becbb6",
   "metadata": {},
   "source": [
    "Let's prepare one of our sample images as a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c78714-460e-40c7-b47d-2685f4b668b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/redhat-dog.jpg'\n",
    "transformed_image, scaling, padding = preprocess(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497994c1-3dd3-4e42-8eca-8a30149a4559",
   "metadata": {},
   "source": [
    "We also need to know the class labels of the objects the model has been trained to detect. In case of the default YOLO v5 model, we can take the default class labels defined in the _classes_ module.\n",
    "If you want to test a custom model, replace `coco_classes` with the list of your custom class labels, e.g.\n",
    "\n",
    "`['Laptop', 'Computer keyboard', 'Table']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842176a-27b0-4750-bc65-4fe107cb5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = coco_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb9cf-48c6-438c-a776-e06d013dcd0c",
   "metadata": {},
   "source": [
    "We'll now need to package the preprocessed image into a format that the model server can consume. RHODS Model Serving implements a generic prediction interface that allows to query the typical model formats through the HTTP POST method using a JSON request body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdc026-6119-4749-ab98-44d1828e64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(image):\n",
    "    payload = {\n",
    "        'inputs': [\n",
    "            {\n",
    "                'name': 'images',\n",
    "                'shape': [1, 3, 640, 640],\n",
    "                'datatype': 'FP32',\n",
    "                'data': image.flatten().tolist(),\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a32e3-5202-480c-bac7-3a12706ca963",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = serialize(transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d859e1-f9d1-4801-be38-8db71cf8e31e",
   "metadata": {},
   "source": [
    "Let's now send the serialized image to the model server. The inference results will also be returned in a generic JSON structure, which we can unpack straightaway. We'll also apply the post-processing function we defined in the previous notebook to extract the familiar object properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb6c3-43d0-4fbb-a830-286c118218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_request(payload, prediction_url, classes_count):\n",
    "    raw_response = post(prediction_url, json=payload)\n",
    "    try:\n",
    "        response = raw_response.json()\n",
    "    except:\n",
    "        print(f'Failed to deserialize service response.\\n'\n",
    "              f'Status code: {raw_response.status_code}\\n'\n",
    "              f'Response body: {raw_response.text}')\n",
    "    try:\n",
    "        model_output = response['outputs']\n",
    "    except:\n",
    "        print(f'Failed to extract model output from service response.\\n'\n",
    "              f'Service response: {response}')\n",
    "    unpacked_output = _unpack(model_output, classes_count)\n",
    "    return unpacked_output\n",
    "\n",
    "\n",
    "def _unpack(model_output, classes_count):\n",
    "    arr = np.array(model_output[0]['data'])\n",
    "    # Get the response data as a NumPy Array\n",
    "\n",
    "    output = torch.tensor(arr)  # Create a tensor from array\n",
    "    prediction_columns_number = 5 + classes_count\n",
    "    # Model returns model returns [xywh, conf, class0, class1, ...]\n",
    "\n",
    "    output = output.reshape(\n",
    "        1,\n",
    "        int(int(output.shape[0])/prediction_columns_number),\n",
    "        prediction_columns_number\n",
    "    )  # Reshape the flat array prediction\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66568dae-81cd-41cd-80fd-645c39a08755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_objects = rest_request(payload, prediction_url, len(class_labels))\n",
    "objects = postprocess(raw_objects, class_labels)\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baed58-595b-49ff-86ed-c9921368a1a8",
   "metadata": {},
   "source": [
    "Let's now visualize the result as we did when we were experimenting with the model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96301c5-5198-420e-9ab6-3efd9e8e844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_boxes(image_path, objects, scaling, padding, class_labels)\n",
    "\n",
    "draw_boxes(image_path, *objects[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c64ff-f6d2-4bfa-8417-2885c0b94ee7",
   "metadata": {},
   "source": [
    "We were able to reproduce the object detection example from the previous notebook, so we can consume the deployed model as expected.\n",
    "\n",
    "In the next notebook, we'll do the same thing using the gRPC protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495133a-2f62-4c9e-8071-df0c3135a50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
